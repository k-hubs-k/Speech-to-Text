{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac48e97",
   "metadata": {},
   "source": [
    "# Definir les etiquette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d540f588",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000,)\n"
     ]
    }
   ],
   "source": [
    "# Supposons que vous avez une liste de labels pour chaque fichier audio\n",
    "labels_train = [\n",
    "    \"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\n",
    "    \"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\n",
    "    \"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\n",
    "    \"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\n",
    "    \"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\n",
    "    \"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\n",
    "    \"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\n",
    "    \"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\n",
    "    \"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\n",
    "    \"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\n",
    "    \"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\n",
    "    \"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\n",
    "    \"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\n",
    "    \"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\n",
    "    \"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\"zero\",\n",
    "    \"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\n",
    "    \"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\n",
    "    \"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\n",
    "    \"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\n",
    "    \"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\n",
    "    \"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\n",
    "    \"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\n",
    "    \"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\n",
    "    \"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\n",
    "    \"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\n",
    "    \"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\n",
    "    \"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\n",
    "    \"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\n",
    "    \"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\n",
    "    \"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\"one\",\n",
    "    \"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\n",
    "    \"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\n",
    "    \"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\n",
    "    \"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\n",
    "    \"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\n",
    "    \"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\n",
    "    \"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\n",
    "    \"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\n",
    "    \"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\n",
    "    \"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\n",
    "    \"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\n",
    "    \"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\n",
    "    \"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\n",
    "    \"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\n",
    "    \"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\"two\",\n",
    "    \"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\n",
    "    \"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\n",
    "    \"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\n",
    "    \"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\n",
    "    \"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\n",
    "    \"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\n",
    "    \"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\n",
    "    \"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\n",
    "    \"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\n",
    "    \"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\n",
    "    \"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\n",
    "    \"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\n",
    "    \"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\n",
    "    \"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\n",
    "    \"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\"three\",\n",
    "    \"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\n",
    "    \"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\n",
    "    \"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\n",
    "    \"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\n",
    "    \"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\n",
    "    \"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\n",
    "    \"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\n",
    "    \"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\n",
    "    \"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\n",
    "    \"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\n",
    "    \"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\n",
    "    \"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\n",
    "    \"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\n",
    "    \"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\n",
    "    \"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\"four\",\n",
    "    \"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\n",
    "    \"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\n",
    "    \"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\n",
    "    \"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\n",
    "    \"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\n",
    "    \"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\n",
    "    \"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\n",
    "    \"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\n",
    "    \"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\n",
    "    \"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\n",
    "    \"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\n",
    "    \"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\n",
    "    \"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\n",
    "    \"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\n",
    "    \"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\"five\",\n",
    "    \"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\n",
    "    \"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\n",
    "    \"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\n",
    "    \"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\n",
    "    \"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\n",
    "    \"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\n",
    "    \"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\n",
    "    \"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\n",
    "    \"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\n",
    "    \"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\n",
    "    \"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\n",
    "    \"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\n",
    "    \"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\n",
    "    \"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\n",
    "    \"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\"six\",\n",
    "    \"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\n",
    "    \"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\n",
    "    \"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\n",
    "    \"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\n",
    "    \"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\n",
    "    \"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\n",
    "    \"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\n",
    "    \"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\n",
    "    \"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\n",
    "    \"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\n",
    "    \"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\n",
    "    \"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\n",
    "    \"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\n",
    "    \"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\n",
    "    \"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\"seven\",\n",
    "    \"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\n",
    "    \"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\n",
    "    \"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\n",
    "    \"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\n",
    "    \"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\n",
    "    \"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\n",
    "    \"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\n",
    "    \"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\n",
    "    \"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\n",
    "    \"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\n",
    "    \"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\n",
    "    \"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\n",
    "    \"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\n",
    "    \"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\n",
    "    \"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\"height\",\n",
    "    \"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\n",
    "    \"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\n",
    "    \"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\n",
    "    \"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\n",
    "    \"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\n",
    "    \"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\n",
    "    \"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\n",
    "    \"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\n",
    "    \"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\n",
    "    \"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\n",
    "    \"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\n",
    "    \"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\n",
    "    \"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\n",
    "    \"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\n",
    "    \"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\",\"nine\"\n",
    "]\n",
    "\n",
    "# Convertir les labels en un format numérique (par exemple, utiliser un encodage one-hot)\n",
    "for i in range(len(labels_train)):\n",
    "    # Conversion en minuscules\n",
    "    labels_train[i] = labels_train[i].lower()\n",
    "    # Suppression de la ponctuation\n",
    "    labels_train[i] = re.sub(r'[^\\w\\s]', '', labels_train[i])\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(labels_train)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torchaudio\n",
    "from torchvision.transforms import Compose\n",
    "from torchaudio.transforms import MelSpectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece3d635",
   "metadata": {},
   "source": [
    "# entraînement du modèle de classification vocale en utilisant PyTorch et les caractéristiques MFCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 13, 38)\n"
     ]
    }
   ],
   "source": [
    "# Diviser X et y en un ensemble d'entraînement (80%) et un ensemble de validation (20%)\n",
    "X = np.load(\"mfcc_feature2.npy\")\n",
    "print(X.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=34)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61f11aae",
   "metadata": {
    "metadata": {},
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/500 [00:17<2:22:00, 17.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  1.28% \n",
      "valid_acc =  28.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/500 [01:03<1:21:10,  9.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.399% \n",
      "valid_acc =  8.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 11/500 [01:50<1:17:00,  9.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.384% \n",
      "valid_acc =  14.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 16/500 [02:38<1:16:05,  9.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.375% \n",
      "valid_acc =  23.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 21/500 [03:23<1:13:18,  9.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.353% \n",
      "valid_acc =  28.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 26/500 [04:09<1:12:23,  9.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.334% \n",
      "valid_acc =  32.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 31/500 [04:55<1:11:34,  9.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.311% \n",
      "valid_acc =  32.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 36/500 [05:42<1:11:52,  9.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.294% \n",
      "valid_acc =  35.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 41/500 [06:28<1:10:49,  9.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.273% \n",
      "valid_acc =  44.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 46/500 [07:14<1:09:13,  9.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.252% \n",
      "valid_acc =  48.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 51/500 [08:01<1:10:30,  9.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.23% \n",
      "valid_acc =  53.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 56/500 [08:48<1:09:02,  9.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.212% \n",
      "valid_acc =  56.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 61/500 [09:35<1:09:29,  9.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.192% \n",
      "valid_acc =  61.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 66/500 [10:21<1:08:14,  9.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.174% \n",
      "valid_acc =  64.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 71/500 [11:09<1:06:58,  9.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.176% \n",
      "valid_acc =  61.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 76/500 [11:55<1:06:17,  9.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.152% \n",
      "valid_acc =  69.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 81/500 [12:42<1:05:08,  9.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.142% \n",
      "valid_acc =  72.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 86/500 [13:28<1:02:40,  9.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.128% \n",
      "valid_acc =  74.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 91/500 [14:14<1:03:35,  9.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.119% \n",
      "valid_acc =  76.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 96/500 [15:00<1:02:13,  9.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.114% \n",
      "valid_acc =  77.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 101/500 [15:46<1:01:22,  9.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.107% \n",
      "valid_acc =  77.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 106/500 [16:36<1:03:45,  9.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.099% \n",
      "valid_acc =  80.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 111/500 [17:22<59:41,  9.21s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.0963% \n",
      "valid_acc =  81.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 116/500 [18:08<58:51,  9.20s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.0965% \n",
      "valid_acc =  80.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 121/500 [18:54<58:35,  9.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.0926% \n",
      "valid_acc =  81.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 126/500 [19:41<58:15,  9.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.0908% \n",
      "valid_acc =  82.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 131/500 [20:28<56:56,  9.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.0897% \n",
      "valid_acc =  82.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 136/500 [21:13<54:53,  9.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.0909% \n",
      "valid_acc =  83.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 141/500 [21:59<54:39,  9.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.0936% \n",
      "valid_acc =  82.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 146/500 [22:45<54:24,  9.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.0946% \n",
      "valid_acc =  82.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 151/500 [23:30<52:36,  9.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.0948% \n",
      "valid_acc =  82.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 156/500 [24:15<51:37,  9.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.0968% \n",
      "valid_acc =  82.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 161/500 [25:03<53:26,  9.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.0987% \n",
      "valid_acc =  83.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 166/500 [25:49<52:05,  9.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.102% \n",
      "valid_acc =  82.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 171/500 [26:36<51:12,  9.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.102% \n",
      "valid_acc =  83.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 176/500 [27:23<51:03,  9.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.102% \n",
      "valid_acc =  83.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 181/500 [28:09<48:51,  9.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.103% \n",
      "valid_acc =  84.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 186/500 [28:54<47:38,  9.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.103% \n",
      "valid_acc =  83.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 191/500 [29:39<46:22,  9.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.105% \n",
      "valid_acc =  83.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 196/500 [30:24<45:47,  9.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.106% \n",
      "valid_acc =  83.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 201/500 [31:10<45:27,  9.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.106% \n",
      "valid_acc =  83.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 206/500 [31:55<44:01,  8.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.107% \n",
      "valid_acc =  83.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 211/500 [32:40<43:47,  9.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.107% \n",
      "valid_acc =  83.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 216/500 [33:26<43:20,  9.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.108% \n",
      "valid_acc =  83.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 221/500 [34:12<43:18,  9.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.108% \n",
      "valid_acc =  83.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 226/500 [34:58<41:51,  9.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.109% \n",
      "valid_acc =  84.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 231/500 [35:44<40:38,  9.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.11% \n",
      "valid_acc =  83.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 236/500 [36:29<39:41,  9.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.11% \n",
      "valid_acc =  84.2%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 241/500 [37:15<39:23,  9.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.111% \n",
      "valid_acc =  84.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 246/500 [38:00<38:11,  9.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.111% \n",
      "valid_acc =  84.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 251/500 [38:45<37:18,  8.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.112% \n",
      "valid_acc =  84.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 256/500 [39:30<36:17,  8.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.113% \n",
      "valid_acc =  84.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 261/500 [40:15<35:31,  8.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.113% \n",
      "valid_acc =  84.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 266/500 [41:00<35:05,  9.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.114% \n",
      "valid_acc =  84.3%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 271/500 [41:46<35:09,  9.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.114% \n",
      "valid_acc =  83.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 276/500 [42:33<35:07,  9.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.115% \n",
      "valid_acc =  84.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 281/500 [43:19<33:38,  9.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.116% \n",
      "valid_acc =  84.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 286/500 [44:04<32:31,  9.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.116% \n",
      "valid_acc =  84.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 291/500 [44:51<32:11,  9.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.116% \n",
      "valid_acc =  83.7%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 296/500 [45:37<31:48,  9.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.117% \n",
      "valid_acc =  83.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 301/500 [46:25<31:07,  9.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.117% \n",
      "valid_acc =  83.5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 306/500 [47:12<30:55,  9.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.117% \n",
      "valid_acc =  84.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 311/500 [48:00<29:57,  9.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.118% \n",
      "valid_acc =  83.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 316/500 [48:46<28:10,  9.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_loss =  0.118% \n",
      "valid_acc =  83.8%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 317/500 [49:03<28:19,  9.29s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 89\u001b[0m\n\u001b[0;32m     86\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     88\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 89\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     92\u001b[0m acc \u001b[38;5;241m=\u001b[39m accuracy(outputs, labels)\n",
      "File \u001b[1;32mc:\\Users\\randy bidy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\randy bidy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\randy bidy\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Définir les hyperparamètres\n",
    "# input_size = X_train.shape[1]  # Nombre de coefficients MFCC\n",
    "\n",
    "input_size = 38\n",
    "sequence_length = 13 # ou 492\n",
    "hidden_size = 1024  # Taille de la couche cachée\n",
    "num_classes = y.shape[0]  # Nombre de classes (mots/phrases)\n",
    "num_epochs = 500\n",
    "\n",
    "batch_size = len(X_train)\n",
    "learning_rate = 0.001\n",
    " \n",
    "# modification ici\n",
    "num_layers = 2 \n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#mfcc_features = np.random.rand(100, 13)\n",
    "#labels = np.random.randint(0, 10, size=100)\n",
    "\n",
    "# Convertir les données en tensors PyTorch\n",
    "X_train_tensor = torch.Tensor(X_train)\n",
    "X_test_tensor = torch.Tensor(X_test)\n",
    "y_train_tensor = torch.LongTensor(y_train)\n",
    "y_test_tensor = torch.LongTensor(y_test)\n",
    "\n",
    "# Créer des DataLoader PyTorch\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# print(type(train_loader))\n",
    "# Définir l'architecture du modèle\n",
    "class SpeechToTextModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(SpeechToTextModel, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "\n",
    "        out, _ = self.gru(x, h0)\n",
    "        # out : batch_size , sequence_len , hidden_size \n",
    "        # out (N, 13, 1024)\n",
    "        out = out[:, -1, :]\n",
    "        # out (N, 128)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def accuracy(proba_batch, label_batch):\n",
    "    correct = 0\n",
    "    preds = torch.argmax(proba_batch, dim=1)\n",
    "    for i, pred in enumerate(preds):\n",
    "        if pred == label_batch[i]:\n",
    "            correct += 1\n",
    "    return correct / batch_size\n",
    "\n",
    "# Initialiser le modèle\n",
    "model = SpeechToTextModel(input_size, hidden_size, num_layers , num_classes)\n",
    "\n",
    "# Définir la fonction de perte et l'optimiseur\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate) # Utilisation du paramètre weight_decay pour la régularisation L2\n",
    "\n",
    "# Entraîner le modèle\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "test_loss = []\n",
    "test_acc = []\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train()\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        acc = accuracy(outputs, labels)\n",
    "    train_loss.append(loss.item())\n",
    "    train_acc.append(acc)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs) \n",
    "            loss = criterion(outputs, labels)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            if epoch % 5 == 0:\n",
    "                print(f'valid_loss = {100 * loss / total : .3}% \\nvalid_acc = {100 * correct / total : .3}%')\n",
    "\n",
    "        test_loss.append(loss)\n",
    "        test_acc.append(correct / total)\n",
    "print(f'valid_loss = {100 * loss / total : .3}% \\nvalid_acc = {100 * correct / total : .3}%')\n",
    "print(f'Accuracy du neurone sur le test set: {100 * correct / total}%')\n",
    "    \n",
    "print('Entraînement terminé.')\n",
    "# Sauvegarder le modèle entraîné\n",
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65690628",
   "metadata": {
    "metadata": {},
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mÉchec du démarrage du Kernel. \n",
      "\u001b[1;31mImpossible de démarrer le noyau « Python 3.12.4 » en raison d’un délai d’attente d’utilisation des ports. \n",
      "\u001b[1;31mPour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_loss, label=\"train loss\")\n",
    "plt.plot(test_loss, label=\"test loss\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_acc, label=\"train acc\")\n",
    "plt.plot(test_acc, label=\"test acc\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mÉchec du démarrage du Kernel. \n",
      "\u001b[1;31mImpossible de démarrer le noyau « Python 3.12.4 » en raison d’un délai d’attente d’utilisation des ports. \n",
      "\u001b[1;31mPour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "# Diviser X et y en un ensemble d'entraînement (80%) et un ensemble de validation (20%)\n",
    "X = np.load(\"mfcc_feature1.npy\")\n",
    "X_train, X_set, y_train, y_set = train_test_split(X, y, test_size=0.2, random_state=34)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_set, y_set, test_size=0.5, random_state=34)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "X_valid = X_valid.reshape(X_valid.shape[0], 1, X_valid.shape[1])\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "# Définir les hyperparamètres\n",
    "input_size = X_train.shape[2]  # Nombre de coefficients MFCC\n",
    "hidden_size = 1024  # Taille de la couche cachée\n",
    "num_classes = y.shape[0]  # Nombre de classes (mots/phrases)\n",
    "num_epochs = 100\n",
    "batch_size = len(X_train)\n",
    "learning_rate = 0.001\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using \", device, \" device...\")\n",
    "\n",
    "# Convertir les données en tensors PyTorch\n",
    "X_train_tensor = torch.Tensor(X_train)\n",
    "X_valid_tensor = torch.Tensor(X_valid)\n",
    "X_test_tensor = torch.Tensor(X_test)\n",
    "y_train_tensor = torch.LongTensor(y_train)\n",
    "y_valid_tensor = torch.LongTensor(y_valid)\n",
    "y_test_tensor = torch.LongTensor(y_test)\n",
    "\n",
    "# Créer des DataLoader PyTorch\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "valid_dataset = TensorDataset(X_valid_tensor, y_valid_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=len(X_valid), shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=len(X_test), shuffle=True)\n",
    "\n",
    "class ActDropNormRNN(nn.Module):\n",
    "    def __init__(self, n_feats, dropout, keep_shape=False):\n",
    "        super(ActDropNormRNN, self).__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.norm = nn.LayerNorm(n_feats)\n",
    "        self.keep_shape = keep_shape\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.transpose(1, 2)\n",
    "        # x = self.norm(self.dropout(F.gelu(x)))\n",
    "        x = self.dropout(F.gelu(self.norm(x)))\n",
    "        if self.keep_shape:\n",
    "            return x.transpose(1, 2)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "\n",
    "class SpeechRecognition(nn.Module):\n",
    "    # hyper_parameters = {\n",
    "    #     \"num_classes\": 29,\n",
    "    #     \"n_feats\": 1131,\n",
    "    #     \"dropout\": 0.1,\n",
    "    #     \"hidden_size\": 1024,\n",
    "    #     \"num_layers\": 1\n",
    "    # }\n",
    "\n",
    "    def __init__(self, hidden_size, num_classes, n_feats, num_layers, dropout):\n",
    "        super(SpeechRecognition, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = ModelRNN(n_feats, hidden_size)  # Utilisation du RNN personnalisé\n",
    "        self.dense = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 128),\n",
    "            nn.LayerNorm(128),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.LayerNorm(128),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "        self.lstm = nn.LSTM(input_size=128, hidden_size=hidden_size,\n",
    "                            num_layers=num_layers, dropout=0.0,\n",
    "                            bidirectional=False)\n",
    "        self.layer_norm2 = nn.LayerNorm(hidden_size)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.final_fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def _init_hidden(self, batch_size):\n",
    "        n, hs = self.num_layers, self.hidden_size\n",
    "        return (torch.zeros(n*1, batch_size, hs),\n",
    "                torch.zeros(n*1, batch_size, hs))\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x = x.squeeze(1)  # batch, feature, time\n",
    "        x = self.rnn(x)  # batch, time, hidden_size\n",
    "        x = self.dense(x) # batch, time, feature\n",
    "        x = x.transpose(0, 1) # time, batch, feature\n",
    "        out, (hn, cn) = self.lstm(x, hidden)\n",
    "        # Ajustement des dimensions de hx et cx\n",
    "        hn = hn.squeeze(0)  # hn devient 2D\n",
    "        cn = cn.squeeze(0)  # cn devient 2D\n",
    "        x = self.dropout2(F.gelu(self.layer_norm2(out)))  # (time, batch, n_class)\n",
    "        return self.final_fc(x), (hn, cn)\n",
    "\n",
    "class ModelRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(ModelRNN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        C0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "\n",
    "        out, _ = self.rnn(x, (h0, C0))\n",
    "        return out\n",
    "\n",
    "class ModelLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, dropout):\n",
    "        super(ModelLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.layer_norm = nn.LayerNorm(hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.final_fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        C0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "\n",
    "        \n",
    "        out, (hn, cn) = self.lstm(x, hidden)\n",
    "        x = self.dropout(F.gelu(self.layer_norm(out)))  # Shape: batch_size, time_steps, hidden_size\n",
    "        return self.final_fc(x), (hn, cn)\n",
    "\n",
    "def accuracy(proba_batch, label_batch):\n",
    "    correct = 0\n",
    "    preds = torch.argmax(proba_batch, dim=1)\n",
    "    for i, pred in enumerate(preds):\n",
    "        if pred == label_batch[i]:\n",
    "            correct += 1\n",
    "    return correct / batch_size\n",
    "\n",
    "# Définition du modèle\n",
    "model = SpeechRecognition(hidden_size=hidden_size, num_classes=num_classes, n_feats=input_size, num_layers=1, dropout=0.1)\n",
    "\n",
    "# Définition de la fonction de perte et de l'optimiseur\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "loss_train = []\n",
    "loss_acc = []\n",
    "# Entraînement du modèle\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs, _ = model(inputs.unsqueeze(1), model._init_hidden(inputs.size(0)))  # Ajout de unsqueeze(1) pour correspondre à la taille du batch\n",
    "        loss = criterion(outputs.squeeze(), labels)  # Ajustement pour correspondre à la taille du batch\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    loss_train.append(epoch_loss)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs, _ = model(inputs.unsqueeze(1), model._init_hidden(inputs.size(0)))\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            # print(outputs.shape)\n",
    "            # correct += (predicted == labels).sum().item()\n",
    "    accuracy = correct / total\n",
    "    loss_acc.append(loss)\n",
    "    # print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "print(\"Entraînement terminé.\")\n",
    "# Sauvegarder le modèle entraîné\n",
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mÉchec du démarrage du Kernel. \n",
      "\u001b[1;31mImpossible de démarrer le noyau « Python 3.12.4 » en raison d’un délai d’attente d’utilisation des ports. \n",
      "\u001b[1;31mPour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "plt.plot(loss_train, label=\"train loss\")\n",
    "plt.plot(loss_acc, label=\"test loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mÉchec du démarrage du Kernel. \n",
      "\u001b[1;31mImpossible de démarrer le noyau « Python 3.12.4 » en raison d’un délai d’attente d’utilisation des ports. \n",
      "\u001b[1;31mPour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "# Charger le modèle depuis le fichier 'model.pth'\n",
    "model = SpeechRecognition(hidden_size=hidden_size, num_classes=len(X_valid), n_feats=input_size, num_layers=1, dropout=0.1)\n",
    "model.load_state_dict(torch.load('model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# Définir le mode d'évaluation sur le GPU s'il est disponible\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "acc = []\n",
    "loss_acc = []\n",
    "for epoch in range(num_epochs):\n",
    "    # Évaluer le modèle sur l'ensemble de validation\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in valid_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs, _ = model(inputs.unsqueeze(1), model._init_hidden(inputs.size(0)))\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            _, predicted = torch.max(outputs.unsqueeze(0).data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    acc.append(accuracy)\n",
    "    loss_acc.append(loss)\n",
    "print(f\"Accuracy on validation set: {100 * accuracy:.6f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4637fe",
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mÉchec du démarrage du Kernel. \n",
      "\u001b[1;31mImpossible de démarrer le noyau « Python 3.12.4 » en raison d’un délai d’attente d’utilisation des ports. \n",
      "\u001b[1;31mPour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "X = np.load(\"mfcc_feature1.npy\")\n",
    "X = torch.Tensor(X)\n",
    "X = X.reshape(X.shape[0], 1, -1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(X)\n",
    "print(output.shape)  # Output shape: (batch_size, seq_length, vocab_size)\n",
    "# Supposons que output soit le tenseur de sortie de votre modèle\n",
    "batch_size, seq_length, vocab_size = output.size()\n",
    "\n",
    "# Convertir les logits en probabilités en utilisant une fonction softmax\n",
    "probs = torch.softmax(output, dim=2)\n",
    "\n",
    "# Sélectionner l'indice du mot le plus probable à chaque pas de temps (décodage glouton)\n",
    "predicted_indices = torch.argmax(probs, dim=2)\n",
    "\n",
    "# Convertir les indices prédits en texte\n",
    "vocab = []\n",
    "for i in range(len(y_train)):\n",
    "    vocab.append(labels_train[y_train[i]])   # Liste des mots dans le vocabulaire\n",
    "\n",
    "predicted_text = []\n",
    "for i in range(batch_size):\n",
    "    text = ' '.join([vocab[idx.item()] for idx in predicted_indices[i]])\n",
    "    predicted_text.append(text)\n",
    "\n",
    "# Afficher le texte prédit pour chaque exemple dans le batch\n",
    "for i, text in enumerate(predicted_text):\n",
    "    print(f\"Exemple {i+1}: {text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mÉchec du démarrage du Kernel. \n",
      "\u001b[1;31mImpossible de démarrer le noyau « Python 3.12.4 » en raison d’un délai d’attente d’utilisation des ports. \n",
      "\u001b[1;31mPour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    tensor_transcription = model(X)\n",
    "\n",
    "# Convertir le tensor en texte (c'est là que vous adapteriez en fonction du retour de votre modèle)\n",
    "text_transcription = \" \".join([str(x) for x in tensor_transcription.tolist()])\n",
    "\n",
    "print(\"Transcription du fichier audio :\")\n",
    "print(text_transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mÉchec du démarrage du Kernel. \n",
      "\u001b[1;31mImpossible de démarrer le noyau « Python 3.12.4 » en raison d’un délai d’attente d’utilisation des ports. \n",
      "\u001b[1;31mPour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "# Chargement de votre modèle pré-entraîné (assurez-vous d'avoir les bonnes instructions pour charger votre modèle spécifique)\n",
    "my_pretrained_model = torch.load(\"model.pth\")\n",
    "\n",
    "# Fonction pour prétraiter les données audio (adapter selon les besoins de votre modèle)\n",
    "def preprocess_audio(audio_file):\n",
    "    # Lire le fichier audio et effectuer le prétraitement nécessaire (par exemple, conversion en MFCC)\n",
    "    # Assurez-vous que la forme et le format des données audio correspondent aux attentes de votre modèle\n",
    "    # Exemple simplifié pour les besoins de l'exemple :\n",
    "    audio_data = np.load(audio_file)\n",
    "    return audio_data\n",
    "\n",
    "# Chemin du fichier audio à traiter\n",
    "audio_file = \"audio_chiffre/3_jackson_3.wav\"\n",
    "\n",
    "# Charger et prétraiter le fichier audio\n",
    "audio_data = preprocess_audio(audio_file)\n",
    "\n",
    "# Utiliser votre modèle pour transcrire le texte du signal audio\n",
    "with torch.no_grad():\n",
    "    text_transcription = my_pretrained_model(audio_data)\n",
    "\n",
    "print(\"Transcription du fichier audio :\")\n",
    "print(text_transcription)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preproce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mÉchec du démarrage du Kernel. \n",
      "\u001b[1;31mImpossible de démarrer le noyau « Python 3.12.4 » en raison d’un délai d’attente d’utilisation des ports. \n",
      "\u001b[1;31mPour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import librosa\n",
    "import numpy as np\n",
    "def correction_accent(audio_file):\n",
    "    signal, sample_rate = audio_file\n",
    "\n",
    "    # Calculer les coefficients cepstraux MFCC\n",
    "    mfccs = librosa.feature.mfcc(y=signal, sr=sample_rate, n_mfcc=13)\n",
    "\n",
    "    # Normaliser les coefficients MFCC\n",
    "    scaler = StandardScaler()\n",
    "    return scaler.fit_transform(mfccs.T).T\n",
    "\n",
    "# Prétraiter les données audio\n",
    "transform = Compose([\n",
    "    torchaudio.transforms.Resample(orig_freq=44100, new_freq=16000),  # Échantillonnage à 16 kHz\n",
    "    MelSpectrogram(n_fft=400, win_length=400, hop_length=160, n_mels=128)  # Créer un spectrogramme Mel\n",
    "])\n",
    "\n",
    "# Passer les données à travers le modèle\n",
    "audio_path = 'norm_temporelle.wav'\n",
    "waveform, sample_rate = torchaudio.load(audio_path)\n",
    "spectrogram = transform(waveform).unsqueeze(0)  # Ajouter une dimension de lot\n",
    "spectrogram = np.array(spectrogram)\n",
    "spectrogram = spectrogram.reshape(-1)\n",
    "# spectrogram = np.array(spectrogram)\n",
    "mfcc = correction_accent((spectrogram, sample_rate))\n",
    "mfcc = torch.Tensor(mfcc)\n",
    "spectrogram = mfcc.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226a0014",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mÉchec du démarrage du Kernel. \n",
      "\u001b[1;31mImpossible de démarrer le noyau « Python 3.12.4 » en raison d’un délai d’attente d’utilisation des ports. \n",
      "\u001b[1;31mPour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "# 1. Charger le modèle\n",
    "model = torch.load('model.pth')\n",
    "# model.eval()\n",
    "\n",
    "# 2. Prétraiter les données audio\n",
    "transform = Compose([\n",
    "    torchaudio.transforms.Resample(orig_freq=44100, new_freq=16000),  # Échantillonnage à 16 kHz\n",
    "    MelSpectrogram(n_fft=400, win_length=400, hop_length=160, n_mels=128)  # Créer un spectrogramme Mel\n",
    "])\n",
    "\n",
    "# 3. Passer les données à travers le modèle\n",
    "audio_path = 'norm_temporelle.wav'\n",
    "waveform, sample_rate = torchaudio.load(audio_path)\n",
    "spectrogram = transform(waveform).unsqueeze(0)  # Ajouter une dimension de lot\n",
    "print(spectrogram.shape)\n",
    "# Si vous utilisez GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(device)\n",
    "# model = model.to(device)\n",
    "spectrogram = spectrogram.to(device)\n",
    "\n",
    "# Obtenir les prédictions\n",
    "with torch.no_grad():\n",
    "    outputs = model(spectrogram)\n",
    "\n",
    "# Appliquer la fonction softmax si nécessaire\n",
    "probs = F.softmax(outputs, dim=1)\n",
    "predictions = torch.argmax(probs, dim=1)\n",
    "\n",
    "# Faire quelque chose avec les prédictions\n",
    "print(\"Prédictions:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad47df1",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mÉchec du démarrage du Kernel. \n",
      "\u001b[1;31mImpossible de démarrer le noyau « Python 3.12.4 » en raison d’un délai d’attente d’utilisation des ports. \n",
      "\u001b[1;31mPour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Phrase à tokenizer\n",
    "sentence = \"Ceci est un exemple de phrase à tokenizer.\"\n",
    "\n",
    "# Tokenisation des mots\n",
    "tokens = word_tokenize(sentence)\n",
    "\n",
    "# Affichage des tokens\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c38fb4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mÉchec du démarrage du Kernel. \n",
      "\u001b[1;31mImpossible de démarrer le noyau « Python 3.12.4 » en raison d’un délai d’attente d’utilisation des ports. \n",
      "\u001b[1;31mPour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Exemple de données texte\n",
    "texts = [\"Ceci est un exemple de phrase.\", \"Voici un autre exemple.\"]\n",
    "\n",
    "# Initialiser le CountVectorizer\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "\n",
    "# Adapter le vectorizer aux données et encoder les données texte\n",
    "encoded_texts = vectorizer.fit_transform(texts)\n",
    "\n",
    "# Afficher les textes encodés\n",
    "print(encoded_texts.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mÉchec du démarrage du Kernel. \n",
      "\u001b[1;31mImpossible de démarrer le noyau « Python 3.12.4 » en raison d’un délai d’attente d’utilisation des ports. \n",
      "\u001b[1;31mPour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "# Exemple de données textuelles\n",
    "# data = [\n",
    "#     \"Je mange une pomme.\",\n",
    "#     \"Il fait beau aujourd'hui.\",\n",
    "#     \"Bonjour, comment ça va ?\"\n",
    "# ]\n",
    "data = labels_train\n",
    "\n",
    "# Tokenisation et création du vocabulaire\n",
    "word_to_index = {}\n",
    "index_to_word = {}\n",
    "for sentence in data:\n",
    "    tokens = sentence.split()\n",
    "    for token in tokens:\n",
    "        if token not in word_to_index:\n",
    "            word_to_index[token] = len(word_to_index)\n",
    "            index_to_word[len(index_to_word)] = token\n",
    "\n",
    "# Encodage des séquences\n",
    "encoded_data = []\n",
    "for sentence in data:\n",
    "    tokens = sentence.split()\n",
    "    encoded_sentence = [word_to_index[token] for token in tokens]\n",
    "    encoded_data.append(encoded_sentence)\n",
    "\n",
    "# Création du Dataset et DataLoader\n",
    "class LanguageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return torch.tensor(self.data[index])\n",
    "\n",
    "dataset = LanguageDataset(encoded_data)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "# Définition du modèle de langue (exemple avec un LSTM)\n",
    "class LanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers):\n",
    "        super(LanguageModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        output, _ = self.lstm(embedded)\n",
    "        output = self.fc(output[-1, :])\n",
    "        return output\n",
    "\n",
    "# Paramètres du modèle\n",
    "vocab_size = len(word_to_index)\n",
    "embedding_dim = 128\n",
    "hidden_dim = 256\n",
    "num_layers = 2\n",
    "\n",
    "# Création du modèle\n",
    "model = LanguageModel(vocab_size, embedding_dim, hidden_dim, num_layers)\n",
    "\n",
    "# Définition de la fonction de coût et de l'optimiseur\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Boucle d'entraînement\n",
    "for epoch in tqdm(range(10)):\n",
    "    total_loss = 0\n",
    "    for batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(batch)\n",
    "        print(f\"output : {output.shape}\")\n",
    "        print(f\"batch : {batch.shape}\")\n",
    "        loss = criterion(output, batch.view(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f'Epoch [{epoch+1}/100], Loss: {total_loss/len(dataloader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mÉchec du démarrage du Kernel. \n",
      "\u001b[1;31mImpossible de démarrer le noyau « Python 3.12.4 » en raison d’un délai d’attente d’utilisation des ports. \n",
      "\u001b[1;31mPour plus d’informations, consultez Jupyter <a href='command:jupyter.viewOutput'>log</a>."
     ]
    }
   ],
   "source": [
    "# Évaluation du modèle (exemples de prédiction)\n",
    "input_test = torch.tensor([[word_to_index[\"one\"], word_to_index[\"three\"], word_to_index[\"three\"], word_to_index[\"three\"], word_to_index[\"one\"]]])\n",
    "output_test = model(input_test)\n",
    "predicted_index = torch.argmax(output_test)\n",
    "predicted_word = index_to_word[predicted_index.item()]\n",
    "print('Predicted Word:', predicted_word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b302cdd1e032ee910f5c889c3360c28564c92ad4f326fc3102e39fbe47faee66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
